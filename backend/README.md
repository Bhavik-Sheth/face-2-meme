# Face-to-Meme Backend

## What This Backend Does

This is a **real-time emotion-based politician meme generator**. It analyzes a user's facial expression from a captured image and returns a matching politician meme based on the detected emotion.

---

## Pipeline Overview

```
User Image â†’ Emotion Detection â†’ Meme Selection â†’ Output Meme
```

### **Stage 1: Emotion Detection**
- Takes a user's face image as input
- Uses **MobileNetV2** deep learning model (`emotion_teller.pth`)
- Trained on FER2013 dataset
- Returns one of 7 emotions: `happy`, `sad`, `angry`, `neutral`, `surprise`, `fear`, `disgust`

### **Stage 2: Meme Selection**
- Takes the detected emotion string
- Randomly selects a matching politician meme from `assets/memes/{emotion}/`
- Copies selected meme to `outputs/final_meme.png` for display

---

## Data Flow

```
1. User captures photo from video feed
   â†“
2. Image â†’ emotion_detector.py â†’ Emotion string ("happy")
   â†“
3. Emotion â†’ politician_selector.py â†’ Random meme selection
   â†“
4. Meme copied to outputs/final_meme.png
   â†“
5. Frontend displays the meme
```

---

## Project Structure

```
backend/
â”œâ”€â”€ main.py                      # FastAPI application entry point
â”œâ”€â”€ requirements.txt             # Python dependencies
â”‚
â”œâ”€â”€ services/                    # Core business logic
â”‚   â”œâ”€â”€ emotion_detector.py      # Stage 1: Emotion detection
â”‚   â”œâ”€â”€ politician_selector.py   # Stage 2: Meme selection
â”‚   â””â”€â”€ meme_retrieval.py       # Wrapper utilities
â”‚
â”œâ”€â”€ routes/                      # API endpoints
â”‚   â”œâ”€â”€ capture_routes.py        # POST /capture endpoint
â”‚   â””â”€â”€ meme_routes.py          # Legacy routes
â”‚
â”œâ”€â”€ models/                      # ML models
â”‚   â””â”€â”€ emotion_teller.pth      # Your emotion detection model
â”‚
â”œâ”€â”€ assets/memes/               # Meme repository (organized by emotion)
â”‚   â”œâ”€â”€ happy/
â”‚   â”œâ”€â”€ sad/
â”‚   â”œâ”€â”€ angry/
â”‚   â”œâ”€â”€ neutral/
â”‚   â”œâ”€â”€ surprise/
â”‚   â”œâ”€â”€ fear/
â”‚   â””â”€â”€ disgust/
â”‚
â”œâ”€â”€ outputs/                    # Generated output
â”‚   â””â”€â”€ final_meme.png         # Final meme ready for display
â”‚
â””â”€â”€ data/
    â””â”€â”€ meme_map.csv           # Emotion-to-folder mapping
```

---

## Key Features

âœ… **MobileNetV2 Emotion Detection** - Deep learning model trained on FER2013 dataset  
âœ… **GPU/CPU Support** - Automatic device detection (CUDA/CPU)  
âœ… **High Accuracy** - Custom classifier with dropout and batch normalization  
âœ… **Meme Selection** - Randomly picks matching politician memes  
âœ… **Output Management** - Copies memes to standard output location  
âœ… **Placeholder Mode** - Works without model for testing  
âœ… **Error Handling** - Comprehensive error messages  
âœ… **Modular Design** - Easy to extend and modify  

---

## Tech Stack

- **Framework:** FastAPI (async Python web framework)
- **Deep Learning:** PyTorch, TorchVision (MobileNetV2 architecture)
- **ML Libraries:** scikit-learn, TensorFlow
- **Image Processing:** Pillow, OpenCV, NumPy
- **Model:** MobileNetV2 with custom 7-class emotion classifier
- **Dependencies:** See `requirements.txt`

---

## Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Add Your Model
## Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Add Your Model
Place your trained MobileNetV2 model file at `models/emotion_teller.pth`  
*(Must be state_dict format with 7-class classifier)*

### 3. Add Meme Images
Add politician meme images to emotion subfolders:
- `assets/memes/happy/politician1.png`
- `assets/memes/sad/politician2.png`
- etc.

### 4. Test the Pipeline
```bash
python test_complete_pipeline.py
```

### 5. Run the Server
```bash
uvicorn main:app --reload
```

---

## Testing

**Test Complete Pipeline:**
```bash
python test_complete_pipeline.py
```

**Test Stage 1 (Emotion Detection):**
```python
from services.emotion_detector import detect_emotion_from_image
emotion = detect_emotion_from_image("test_image.png")
print(emotion)  # Output: "happy"
```

**Test Stage 2 (Meme Selection):**
```python
from services.politician_selector import select_and_output_meme
result = select_and_output_meme("happy")
print(result['output_path'])  # Output: "outputs/final_meme.png"
```

---

## Current Status

| Component | Status |
|-----------|--------|
| Stage 1 - Emotion Detection | âœ… Coded (placeholder until model added) |
| Stage 2 - Meme Selection | âœ… Coded and working |
| Output Management | âœ… Working |
| Pipeline Integration | âœ… Working |
| API Endpoints | ðŸ”„ Placeholder (needs implementation) |

---

## Use Case

An interactive application where users can:
1. Capture their facial expression via webcam
2. Get instant emotion detection
3. Receive a matching politician meme
4. Share or display the meme

Perfect for entertainment, social media engagement, or hackathon demos.

---

## For More Details

See `Function.md` for detailed implementation documentation.
